{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from pylab import *\n",
    "from matplotlib import gridspec\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "cdict = {'red': ((0.0, 1.0, 1.0),\n",
    "                 (0.125, 1.0, 1.0),\n",
    "                 (0.25, 1.0, 1.0),\n",
    "                 (0.5625, 1.0, 1.0),\n",
    "                 (1.0, 0.0, 0.0)),\n",
    "         'green': ((0.0, 0.0, 0.0),\n",
    "                   (0.25, 0.0, 0.0),\n",
    "                   (0.5625, 1.0, 1.0),\n",
    "                   (1.0, 1.0, 1.0)),\n",
    "         'blue': ((0.0, 0.0, 0.0),\n",
    "                  (0.5, 0.0, 0.0),\n",
    "                  (1.0, 0.0, 0.0))}\n",
    "my_cmap = matplotlib.colors.LinearSegmentedColormap('my_colormap',cdict,256)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73014, 10, 5, 9)\n",
      "(73014,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "(samples,labels) = pickle.load( open( \"data_new.p\", \"rb\" ) )\n",
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15840, 10, 5, 9)\n",
      "(15840, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def class_balance(samples,labels):\n",
    "    samples0 = samples[labels==0,:,:,:]\n",
    "    samples1 = samples[labels==1,:,:,:]\n",
    "    selected = np.random.choice(len(samples0), len(samples1), replace=False)\n",
    "    samples0 = samples0[selected,:,:,:]\n",
    "    labels0 = np.zeros((len(samples0)))\n",
    "    labels1 = np.ones((len(samples1)))\n",
    "    samples = np.concatenate((samples0,samples1),axis=0)\n",
    "    labels = np.concatenate((labels0,labels1),axis=0)\n",
    "    samples, labels = shuffle(samples, labels)\n",
    "    return samples, labels\n",
    "samples, labels = class_balance(samples,labels)\n",
    "one_hot_labels = np.zeros((labels.shape[0],2))\n",
    "one_hot_labels[labels==0,0]=1\n",
    "one_hot_labels[labels==1,1]=1\n",
    "print(samples.shape)\n",
    "print(one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMax_Normalization(samples):\n",
    "    samples_shape = samples.shape\n",
    "    samples = np.reshape(samples,(samples_shape[0],samples_shape[1]*samples_shape[2]*samples_shape[3]))\n",
    "    scaler = MinMaxScaler().fit(samples)\n",
    "    samples_normalized = scaler.transform(samples)\n",
    "    samples_normalized = np.reshape(samples_normalized,(samples_shape[0],samples_shape[1],samples_shape[2],samples_shape[3]))\n",
    "    return samples_normalized, scaler\n",
    "    \n",
    "samples_scaled, scaler = MinMax_Normalization(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15840, 10, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "def feature_select(samples_scaled,features):\n",
    "    return samples_scaled[:,:,:,features]\n",
    "\n",
    "features = [0,1,2,7,8]\n",
    "samples_scaled = feature_select(samples_scaled,features)\n",
    "print(samples_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape, Dense, Convolution2D, Deconvolution2D, Flatten, Input, Dropout, MaxPooling2D, Activation\n",
    "from keras.models import model_from_json\n",
    "from keras.activations import relu, softmax, linear\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.6139 - acc: 0.6599     \n",
      "Epoch 2/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5806 - acc: 0.6921     \n",
      "Epoch 3/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5746 - acc: 0.6955     \n",
      "Epoch 4/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5720 - acc: 0.7011     \n",
      "Epoch 5/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5707 - acc: 0.7008     \n",
      "Epoch 6/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5664 - acc: 0.7039     \n",
      "Epoch 7/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5637 - acc: 0.7032     \n",
      "Epoch 8/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5588 - acc: 0.7080     \n",
      "Epoch 9/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5583 - acc: 0.7085     \n",
      "Epoch 10/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5546 - acc: 0.7157     \n",
      "Epoch 11/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5530 - acc: 0.7111     \n",
      "Epoch 12/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5510 - acc: 0.7114     \n",
      "Epoch 13/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5488 - acc: 0.7162     \n",
      "Epoch 14/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5464 - acc: 0.7170     \n",
      "Epoch 15/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5398 - acc: 0.7210     \n",
      "Epoch 16/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5395 - acc: 0.7203     \n",
      "Epoch 17/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5356 - acc: 0.7247     \n",
      "Epoch 18/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5327 - acc: 0.7237     \n",
      "Epoch 19/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5326 - acc: 0.7226     \n",
      "Epoch 20/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5270 - acc: 0.7293     \n",
      "Epoch 21/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5230 - acc: 0.7285     \n",
      "Epoch 22/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5208 - acc: 0.7328     \n",
      "Epoch 23/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5171 - acc: 0.7365     \n",
      "Epoch 24/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5139 - acc: 0.7352     \n",
      "Epoch 25/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5092 - acc: 0.7402     \n",
      "Epoch 26/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5069 - acc: 0.7382     \n",
      "Epoch 27/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5040 - acc: 0.7422     \n",
      "Epoch 28/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.5052 - acc: 0.7428     \n",
      "Epoch 29/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4975 - acc: 0.7439     \n",
      "Epoch 30/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4963 - acc: 0.7471     \n",
      "Epoch 31/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4904 - acc: 0.7520     \n",
      "Epoch 32/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4874 - acc: 0.7533     \n",
      "Epoch 33/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4837 - acc: 0.7545     \n",
      "Epoch 34/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4831 - acc: 0.7554     \n",
      "Epoch 35/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4792 - acc: 0.7578     \n",
      "Epoch 36/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4742 - acc: 0.7617     \n",
      "Epoch 37/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4702 - acc: 0.7638     \n",
      "Epoch 38/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4693 - acc: 0.7643     \n",
      "Epoch 39/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4668 - acc: 0.7661     \n",
      "Epoch 40/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4608 - acc: 0.7708     \n",
      "Epoch 41/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4628 - acc: 0.7673     \n",
      "Epoch 42/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4566 - acc: 0.7730     \n",
      "Epoch 43/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4524 - acc: 0.7708     \n",
      "Epoch 44/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4523 - acc: 0.7752     \n",
      "Epoch 45/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4498 - acc: 0.7741     \n",
      "Epoch 46/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4468 - acc: 0.7780     \n",
      "Epoch 47/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4485 - acc: 0.7742     \n",
      "Epoch 48/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4439 - acc: 0.7764     \n",
      "Epoch 49/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4430 - acc: 0.7768     \n",
      "Epoch 50/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4387 - acc: 0.7824     \n",
      "Epoch 51/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4378 - acc: 0.7790     \n",
      "Epoch 52/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4380 - acc: 0.7863     \n",
      "Epoch 53/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4370 - acc: 0.7826     \n",
      "Epoch 54/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4379 - acc: 0.7803     \n",
      "Epoch 55/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4301 - acc: 0.7864     \n",
      "Epoch 56/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4272 - acc: 0.7896     \n",
      "Epoch 57/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4271 - acc: 0.7837     \n",
      "Epoch 58/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4299 - acc: 0.7875     \n",
      "Epoch 59/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4245 - acc: 0.7905     \n",
      "Epoch 60/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4209 - acc: 0.7954     \n",
      "Epoch 61/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4186 - acc: 0.7951     \n",
      "Epoch 62/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4189 - acc: 0.7931     \n",
      "Epoch 63/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4157 - acc: 0.7965     \n",
      "Epoch 64/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4211 - acc: 0.7934     \n",
      "Epoch 65/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4097 - acc: 0.8007     \n",
      "Epoch 66/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4091 - acc: 0.8001     \n",
      "Epoch 67/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4113 - acc: 0.7969     \n",
      "Epoch 68/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4072 - acc: 0.8018     \n",
      "Epoch 69/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4109 - acc: 0.7987     \n",
      "Epoch 70/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4035 - acc: 0.8006     \n",
      "Epoch 71/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4092 - acc: 0.8024     \n",
      "Epoch 72/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4035 - acc: 0.8047     \n",
      "Epoch 73/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3975 - acc: 0.8044     \n",
      "Epoch 74/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3983 - acc: 0.8063     \n",
      "Epoch 75/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3992 - acc: 0.8070     \n",
      "Epoch 76/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.4016 - acc: 0.8074     \n",
      "Epoch 77/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3921 - acc: 0.8115     \n",
      "Epoch 78/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3998 - acc: 0.8072     \n",
      "Epoch 79/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3920 - acc: 0.8100     \n",
      "Epoch 80/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3940 - acc: 0.8086     \n",
      "Epoch 81/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3919 - acc: 0.8100     \n",
      "Epoch 82/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3854 - acc: 0.8152     \n",
      "Epoch 83/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3819 - acc: 0.8147     \n",
      "Epoch 84/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3852 - acc: 0.8165     \n",
      "Epoch 85/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3808 - acc: 0.8176     \n",
      "Epoch 86/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3833 - acc: 0.8157     \n",
      "Epoch 87/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3851 - acc: 0.8145     \n",
      "Epoch 88/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3826 - acc: 0.8169     \n",
      "Epoch 89/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3751 - acc: 0.8217     \n",
      "Epoch 90/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3812 - acc: 0.8156     \n",
      "Epoch 91/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3755 - acc: 0.8197     \n",
      "Epoch 92/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3763 - acc: 0.8212     \n",
      "Epoch 93/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3690 - acc: 0.8204     \n",
      "Epoch 94/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3731 - acc: 0.8210     \n",
      "Epoch 95/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3700 - acc: 0.8228     \n",
      "Epoch 96/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3666 - acc: 0.8235     \n",
      "Epoch 97/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3708 - acc: 0.8237     \n",
      "Epoch 98/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3650 - acc: 0.8269     \n",
      "Epoch 99/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3632 - acc: 0.8287     \n",
      "Epoch 100/100\n",
      "15840/15840 [==============================] - 1s - loss: 0.3602 - acc: 0.8276     \n"
     ]
    }
   ],
   "source": [
    "# deep CNN model\n",
    "\n",
    "model = Sequential()\n",
    "# 10*5*5\n",
    "model.add(Convolution2D(16, 3, 3,input_shape=(10, 5, 5),border_mode='valid'))\n",
    "model.add(ELU())\n",
    "# 8*3*16\n",
    "model.add(Convolution2D(32, 3, 3,border_mode='valid'))\n",
    "model.add(ELU())\n",
    "# 6*1*32\n",
    "model.add(Flatten())\n",
    "# 192\n",
    "model.add(Dense(64))\n",
    "model.add(ELU())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history_object = model.fit(samples_scaled, one_hot_labels, nb_epoch=100, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15840/15840 [==============================] - 1s - loss: 0.6122 - acc: 0.6653     \n",
      "Epoch 2/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5772 - acc: 0.6956     \n",
      "Epoch 3/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5679 - acc: 0.7033     \n",
      "Epoch 4/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5653 - acc: 0.7029     \n",
      "Epoch 5/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5603 - acc: 0.7091     \n",
      "Epoch 6/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5590 - acc: 0.7107     \n",
      "Epoch 7/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5551 - acc: 0.7119     \n",
      "Epoch 8/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5514 - acc: 0.7159     \n",
      "Epoch 9/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5489 - acc: 0.7145     \n",
      "Epoch 10/10\n",
      "15840/15840 [==============================] - 0s - loss: 0.5492 - acc: 0.7128     \n"
     ]
    }
   ],
   "source": [
    "# deep ANN model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(10, 5, 5)))\n",
    "# 192\n",
    "model.add(Dense(64))\n",
    "model.add(ELU())\n",
    "model.add(Dense(32))\n",
    "model.add(ELU())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history_object = model.fit(samples_scaled, one_hot_labels, nb_epoch=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89720249,  0.10279749],\n",
       "       [ 0.9130066 ,  0.08699342],\n",
       "       [ 0.90403706,  0.09596292],\n",
       "       [ 0.93120247,  0.06879755],\n",
       "       [ 0.85641062,  0.14358936],\n",
       "       [ 0.88387764,  0.1161223 ],\n",
       "       [ 0.91124195,  0.08875811],\n",
       "       [ 0.95300812,  0.04699193],\n",
       "       [ 0.86156821,  0.13843176],\n",
       "       [ 0.89209193,  0.10790803]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(samples_scaled[0:10,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_shallow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND]",
   "language": "python",
   "name": "conda-env-CarND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
